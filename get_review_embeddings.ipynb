{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yishanhsieh/llm-segmentation/blob/main/get_review_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Reveiws\n",
        "- Run on A100"
      ],
      "metadata": {
        "id": "bnuygqSD-PIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgCsJuPIxFAX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dR2-84LK8iuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "_Hmw5Aq2xW04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "QhjRxaphxnaq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "vpzo8swTyx1v",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "6mDaeYr9y7Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "eIltOLckyhTr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.2.2\n",
        "!pip install numpy<3.0.0,>=2.0.0"
      ],
      "metadata": {
        "id": "sUNlLKKjW3IG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk"
      ],
      "metadata": {
        "id": "0gCkG9oB7-P_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall gensim"
      ],
      "metadata": {
        "id": "i7Rzd4fCXWaG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "\n",
        "# Tutorial from NLTK: https://www.nltk.org/data.html\n",
        "# train the word2vec model that learns the word meaning in the bubble tea reviews"
      ],
      "metadata": {
        "id": "fx44P5dC6bQg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download() # this one runs endless\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "# punkt explains: https://www.askpython.com/python-modules/nltk-punkt"
      ],
      "metadata": {
        "id": "GcUP9BsS76w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "Pc4vT-4V9X33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"All Reviews.csv\")\n",
        "\n",
        "# df['Rating'] = df['Rating'].str.extract(r\"(\\d+)\")\n",
        "# for i in range(len(df)):\n",
        "#     if df['Reviews'][i] == 'No review text available':\n",
        "#         df = df.drop(i)\n",
        "\n",
        "reviews = df[\"Reviews\"]\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "bkhIyivo9WcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = list(reviews)"
      ],
      "metadata": {
        "id": "sGKtkDI0KDP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "- tutorial: https://radimrehurek.com/gensim/models/word2vec.html"
      ],
      "metadata": {
        "id": "yIjPE_V26buI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return [word for word in tokens if word.isalpha()] # if word is alphabet letters\n",
        "\n",
        "tokenized_reviews = []\n",
        "# tokenize each review\n",
        "for review in reviews:\n",
        "    tokenized_reviews.append(preprocess(review))\n",
        "\n",
        "# tokenized_reviews\n",
        "# [['babo', 'tea'],['I','love', 'this']... ]"
      ],
      "metadata": {
        "id": "i4KBcPlC6e_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=300, window=5, min_count=2, workers=4)"
      ],
      "metadata": {
        "id": "2i3Aq-c-7wwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This func transfers review tokens into vectors\n",
        "def get_w2v_review_vector(tokens, model):\n",
        "\n",
        "    # only keep the word in W2V model's vocabulary\n",
        "    recognized_word_in_review= []\n",
        "    word_vector = []\n",
        "\n",
        "    for w in tokens:\n",
        "        if w in model.wv.key_to_index: # {'the': 0, 'and': 1, 'i': 2,...}\n",
        "            recognized_word_in_review.append(w)\n",
        "\n",
        "    # if a review contains no model vocabuary, set its vector 0\n",
        "    if len(recognized_word_in_review) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    # if has value, get the word vector and calculate the avg\n",
        "    for w in recognized_word_in_review:\n",
        "        word_vector.append(model.wv[w])\n",
        "\n",
        "    review_vector = np.mean(word_vector, axis = 0)\n",
        "    return review_vector"
      ],
      "metadata": {
        "id": "7PzA9CDi7wrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_review_vectors = []\n",
        "for tokens in tokenized_reviews:\n",
        "    vector = get_w2v_review_vector(tokens, w2v_model)\n",
        "    w2v_review_vectors.append(vector)"
      ],
      "metadata": {
        "id": "6U9LEtUI9l3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_review_vectors = np.array(w2v_review_vectors) #convert it into a np array\n",
        "print(w2v_review_vectors.shape)\n",
        "# 607 reviews, each review is represented as 100-D vector"
      ],
      "metadata": {
        "id": "D0O59sLv9mRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize rating & Reshape dimentions: convert 1-5 scale into 0~1"
      ],
      "metadata": {
        "id": "NAsc3kfM9v-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = df[\"Rating\"]\n",
        "normalized_ratings = np.array(ratings, dtype=float) / 5\n",
        "\n",
        "# reshape normalized ratings into (607, 1)\n",
        "reshaped_ratings = normalized_ratings.reshape(-1,1)\n",
        "reshaped_ratings.shape"
      ],
      "metadata": {
        "id": "Dtrogcgp9viM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine normalized ratings with review vectors"
      ],
      "metadata": {
        "id": "dlAJzt5690yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_rating_combined_vectors = np.hstack((w2v_review_vectors, reshaped_ratings))\n",
        "w2v_rating_combined_vectors.shape"
      ],
      "metadata": {
        "id": "JrgefLAd9y2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_list  = list(reviews)"
      ],
      "metadata": {
        "id": "xr9JzxVP_rfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence BERT mini\n",
        "- Usage (Sentence-Transformers)\n",
        "- https://huggingface.co/sentence-transformers\n",
        "- https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
      ],
      "metadata": {
        "id": "ozsPRO1g-FUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "bOOtcGijDC5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ],
      "metadata": {
        "id": "TgpJpPOCDLnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "bert_mini_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "AB8JUQQVDPL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "bert_mini_model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hya1RpHCFMLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "encoded_input = tokenizer(review_list, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "# Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = bert_mini_model(**encoded_input)\n",
        "\n",
        "# Perform pooling\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "# Normalize embeddings\n",
        "bert_mini_embeddings = F.normalize(sentence_embeddings, p=2, dim=1).squeeze().cpu().numpy()"
      ],
      "metadata": {
        "id": "LmMZ1usBDXc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_mini_embeddings.shape"
      ],
      "metadata": {
        "id": "2FYYs345Kn-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_mini_rating_combined_vectors = np.hstack((bert_mini_embeddings, reshaped_ratings))\n",
        "bert_mini_rating_combined_vectors.shape"
      ],
      "metadata": {
        "id": "MrjtI9xLbuYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT (all-mpnet-base-v2)"
      ],
      "metadata": {
        "id": "RGf1cPlvNRrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "bert_model = AutoModelForMaskedLM.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "1FXaOPRyNYCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.config.output_hidden_states = True"
      ],
      "metadata": {
        "id": "mGl9QG9sODXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "bert_model.to(device)"
      ],
      "metadata": {
        "id": "sxM36nwRNd8O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_vector(review, tokenizer, model):\n",
        "\n",
        "\n",
        "    input = tokenizer(review, return_tensors='pt', truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**input)\n",
        "\n",
        "    hidden_states = outputs.hidden_states[-1]  #get hidden states from the last layer\n",
        "\n",
        "    vector = hidden_states.mean(dim=1).squeeze().cpu().numpy()  #average all tokens\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "7HaNDiUfNlV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_bert_vectors = []\n",
        "\n",
        "for review in reviews:\n",
        "    vector = get_bert_vector(review, bert_tokenizer, bert_model)\n",
        "    all_bert_vectors.append(vector)"
      ],
      "metadata": {
        "id": "2_2hou-8No8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "bert_rating_combined_vectors = np.hstack((all_bert_vectors, reshaped_ratings))\n",
        "bert_rating_combined_vectors.shape"
      ],
      "metadata": {
        "id": "v5hc0olgOIaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJbzkrpJbZdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama 2-7b-chat-hf\n",
        "- meta download: https://www.llama.com/llama-downloads/\n",
        "- Huggingface: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "- [Github tutorial](https://github.com/meta-llama/llama-models?fbclid=IwZXh0bgNhZW0CMTAAAR5flYgamnz7bViaAtMQsPvPWGc7jCd69MsAmom7zGFl6Mb9ckvqDYBeACJirg_aem_vjalf1yaPdUasJh9lNKd_g)"
      ],
      "metadata": {
        "id": "WvRgVMD99ofZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "llama_model.config.output_hidden_states = True"
      ],
      "metadata": {
        "id": "pbFPiVbxx64e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "llama_model.to(device)"
      ],
      "metadata": {
        "id": "6n1ZfcT0uTxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_llama_vector(review, tokenizer, model):\n",
        "\n",
        "    input = tokenizer(review, return_tensors='pt', truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**input)\n",
        "\n",
        "    hidden_states = outputs.hidden_states[-1]  #get hidden states from the last layer\n",
        "\n",
        "    vector = hidden_states.mean(dim=1).squeeze().cpu().numpy() #average all tokens\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "11L_mDFS-jP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_vectors = []\n",
        "\n",
        "for review in reviews:\n",
        "    vector = get_llama_vector(review, llama_tokenizer, llama_model)\n",
        "    llama_vectors.append(vector)\n"
      ],
      "metadata": {
        "id": "LL1vn_upak3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_rating_combined_vectors = np.hstack((llama_vectors, reshaped_ratings))\n",
        "llama_rating_combined_vectors.shape"
      ],
      "metadata": {
        "id": "nEU1H-wgarKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Falcon"
      ],
      "metadata": {
        "id": "9bzvwJwG99Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "falcon_tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\", trust_remote_code=True)\n",
        "falcon_model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-7b\", trust_remote_code=True)\n",
        "falcon_model.config.output_hidden_states = True"
      ],
      "metadata": {
        "id": "-xvVmTQC15KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "falcon_model.to(device)"
      ],
      "metadata": {
        "id": "s762ywy_59Vk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate vectors by using Transformers"
      ],
      "metadata": {
        "id": "QPbGRnvd-p8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_falcon_vector(review, tokenizer, model):\n",
        "\n",
        "\n",
        "    input = tokenizer(review, return_tensors='pt', truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**input)\n",
        "\n",
        "    hidden_states = outputs.hidden_states[-1]  #get hidden states from the last layer\n",
        "\n",
        "    vector = hidden_states.mean(dim=1).squeeze().cpu().numpy()  #average all tokens\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "oDStgMBGzbYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_falcon_vectors = []\n",
        "\n",
        "for review in reviews:\n",
        "    vector = get_falcon_vector(review, falcon_tokenizer, falcon_model)\n",
        "    all_falcon_vectors.append(vector)\n"
      ],
      "metadata": {
        "id": "Y4EQSfrlIXev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "falcon_rating_combined_vectors = np.hstack((all_falcon_vectors, reshaped_ratings))\n",
        "falcon_rating_combined_vectors.shape"
      ],
      "metadata": {
        "id": "xJ9qb4Y-Lzl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnZPkMxGTucW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kmeans and evaluation (PCA, sil-score)"
      ],
      "metadata": {
        "id": "zmMLGwCfYj_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that calculates Silhouette score and shows PCA plot\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def get_pca_score(model_name, vector):\n",
        "\n",
        "  for k in range(2,6):\n",
        "    kmeans = KMeans(n_clusters = k, random_state=42)\n",
        "    kmeans.fit(vector)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # if only use sil_score, the value is extremly small, so I use cosine similarity for sil score\n",
        "    cosine_dist = pairwise_distances(vector, metric='cosine')\n",
        "    score = silhouette_score(cosine_dist, labels, metric='precomputed')\n",
        "    # print(f\"Silhouette Score for k={k}: {score:.3f}\")\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(vector)\n",
        "    centers_reduced = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='rainbow')\n",
        "    plt.scatter(centers_reduced[:, 0], centers_reduced[:, 1],\n",
        "                marker='X', s=100, c='black')\n",
        "    plt.title(f\"{model_name} + K-Means Clustering (K={k}, Sil_score={score:.3f})\")\n",
        "    plt.xlabel(\"PCA 1\")\n",
        "    plt.ylabel(\"PCA 2\")\n",
        "    plt.colorbar(scatter, label='Cluster')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "G2sjATrnUR01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_barchart(model_name, vector):\n",
        "\n",
        "  k_list = [2,3,4,5] #x\n",
        "  sil_score_list = [] #y\n",
        "\n",
        "  for k in k_list:\n",
        "      kmeans = KMeans(n_clusters = k, random_state=42)\n",
        "      kmeans.fit(vector)\n",
        "      labels = kmeans.labels_\n",
        "      cosine_dist = pairwise_distances(vector, metric='cosine')\n",
        "      score = silhouette_score(cosine_dist, labels, metric='precomputed')\n",
        "      sil_score_list.append(score)\n",
        "\n",
        "  plt.bar(k_list, sil_score_list,width=0.6)\n",
        "  plt.xlabel(\"K\")\n",
        "  plt.xticks(k_list, [str(k) for k in k_list])\n",
        "  plt.ylabel(\"Silhouette Score\")\n",
        "  plt.title(f\"{model_name} + K-Means Clustering\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "UgF0eWI-eDkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### w2v PCA"
      ],
      "metadata": {
        "id": "pra-vt6oZT9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_barchart(\"w2v\", w2v_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "bpLD1YvReAxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the best k value\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(w2v_rating_combined_vectors)\n",
        "df['w2v_cluster'] = clusters\n",
        "\n",
        "df.to_csv('All Reviews_cluster.csv', index=False)"
      ],
      "metadata": {
        "id": "IdILjI7ngrvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pca_score(\"w2v\", w2v_rating_combined_vectors)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rP_2dg23ZXq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Bert mini PCA"
      ],
      "metadata": {
        "id": "dQwg2cg-BSeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_barchart(\"Sentence Bert mini\", bert_mini_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "Et_Nts4rKuuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pca_score(\"BERT-mini\", bert_mini_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "7Kwch08IcSkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT mpnet PCA"
      ],
      "metadata": {
        "id": "9BUgBqTEZBrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_barchart(\"BERT-mpnet\", bert_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "e_Kd8BCthxzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pca_score(\"BERT\", bert_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "trKxPoVVXamR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### falcon PCA"
      ],
      "metadata": {
        "id": "iLsUQyfgaf9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_barchart(\"falcon\", falcon_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "DxRBue8Dh_Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the best k value\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(falcon_rating_combined_vectors)\n",
        "df['falcon_cluster'] = clusters\n",
        "\n",
        "df.to_csv('All Reviews_cluster.csv', index=False)"
      ],
      "metadata": {
        "id": "eflvMDzkiEp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pca_score(\"falcon\", falcon_rating_combined_vectors)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pT7vyFAJajWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### llama PCA"
      ],
      "metadata": {
        "id": "AsRMx_gDY9Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_barchart(\"llama\", llama_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "KRfafDhgwnYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the best k value\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(llama_rating_combined_vectors)\n",
        "df['llama_cluster'] = clusters\n",
        "\n",
        "df.to_csv('All Reviews_cluster_llama.csv', index=False)"
      ],
      "metadata": {
        "id": "Mb0ZVljhw99o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pca_score(\"llama\", llama_rating_combined_vectors)"
      ],
      "metadata": {
        "id": "mO_OJk0NxHJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze cluster ratings"
      ],
      "metadata": {
        "id": "DTsTexmzcgY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.groupby(\"cluster\")[\"rating\"].mean()"
      ],
      "metadata": {
        "id": "UhE5mdI9cksm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster = pd.read_csv(\"All Reviews_cluster.csv\")\n",
        "\n",
        "df_llama_cluster = pd.read_csv(\"All Reviews_cluster_llama.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EwGrGMqhFYMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster.head()"
      ],
      "metadata": {
        "id": "ji-jjjSjGyyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llama_cluster.head()"
      ],
      "metadata": {
        "id": "H2PFGLNLG1ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster.groupby('w2v_cluster')['Rating'].mean()"
      ],
      "metadata": {
        "id": "_XFZqxPLFnS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster['w2v_cluster'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "vn4nYAJqFwzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster.groupby('falcon_cluster')['Rating'].mean()"
      ],
      "metadata": {
        "id": "m23-PtS8FzOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster['falcon_cluster'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "Z7YFGdIZF1Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llama_cluster.groupby(\"llama_cluster\")[\"Rating\"].mean()"
      ],
      "metadata": {
        "id": "IPHktkvdGWMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llama_cluster['llama_cluster'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "5VUIGqtXHJCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}