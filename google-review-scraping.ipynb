{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install beautifulsoup4\n",
    "# pip install selenium\n",
    "# pip install webdriver\n",
    "# pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# selenium.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Replace with your local ChromeDriver path\n",
    "CHROMEDRIVER_PATH = r\"C:\\Users\\yisha\\Desktop\\2025-spring-LLM\\scraping-reviews-from-googlemaps\\Driver\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Use Service properly (Selenium 4+)\n",
    "service = Service(CHROMEDRIVER_PATH)\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape Google Reviews\n",
    "review_data = []\n",
    "\n",
    "def scrape_google_reviews(url):\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for reviews section to load\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        reviews_section = wait.until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'm6QErb XiKgde ')]\")))\n",
    "    except Exception as e:\n",
    "        print(\"Error: Reviews section not found.\", e)\n",
    "        driver.quit()\n",
    "        return\n",
    "    \n",
    "    body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "\n",
    "    for _ in range(3):  # Scroll down a few times to ensure full loading\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        print(\"I am scrolling down(range3)\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "\n",
    "    # Scroll to load more reviews\n",
    "    for _ in range(10):  # Adjust based on number of reviews needed\n",
    "        \n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", reviews_section)\n",
    "        print(\"I am scrolling down\")\n",
    "        time.sleep(3)  # Allow time for reviews to load\n",
    "\n",
    "    # Extract reviews\n",
    "    reviews = driver.find_elements(By.XPATH, \"//div[contains(@class, 'jJc9Ad ')]\")\n",
    "    \n",
    "    for review in reviews:\n",
    "        try:\n",
    "            try:\n",
    "                more_button = review.find_element(By.XPATH, \".//button[contains(@class, 'w8nwRe kyuRq')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(1)           \n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "            text = review.find_element(By.XPATH, \".//span[contains(@class, 'wiI7pd')]\").text\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error extracting review:\", e)\n",
    "            text = \"No review text available\"\n",
    "        \n",
    "        try:\n",
    "            rating = review.find_element(By.XPATH, \".//span[contains(@class, 'kvMYJc')]\").get_attribute(\"aria-label\")\n",
    "        except:\n",
    "            rating = \"No rating available\"\n",
    "\n",
    "\n",
    "        review_data.append((rating, text))\n",
    "\n",
    "    # Close driver\n",
    "    driver.quit()\n",
    "    \n",
    "    # print five to check \n",
    "    for i in range(5):\n",
    "        print(review_data[i])\n",
    "\n",
    "    # save reviews to csv\n",
    "    df = pd.DataFrame(review_data, columns=['Rating', 'Reviews'])\n",
    "\n",
    "    df.to_csv('Tiger Suger Reviews-New York-Korean Town.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "\n",
    "    \n",
    "google_maps_url = \"https://www.google.com/maps/place/TIGER+SUGAR+(KOREATOWN)/@40.7479287,-73.9903825,17z/data=!3m1!5s0x89c2c22a0528649b:0x56c8962ccf06fc51!4m8!3m7!1s0x89c2597c030838e7:0xe3a3de8bf0d82dd0!8m2!3d40.7479247!4d-73.9878076!9m1!1b1!16s%2Fg%2F11nntd7xsk?entry=ttu&g_ep=EgoyMDI1MDMyNS4xIKXMDSoJLDEwMjExNDU1SAFQAw%3D%3D\"\n",
    "scrape_google_reviews(google_maps_url)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(review_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all csv\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "csv_files = glob.glob(\"./dataset/*.csv\")\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "# df_list\n",
    "\n",
    "all_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "all_df['Rating'] = all_df['Rating'].str.extract(r\"(\\d+)\")\n",
    "\n",
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove no reviews\n",
    "for i in range(len(all_df)):\n",
    "    if all_df['Reviews'][i] == 'No review text available':\n",
    "        all_df = all_df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"All Reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 607 entries, 0 to 652\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Rating   607 non-null    object\n",
      " 1   Reviews  607 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()\n",
    "\n",
    "# 674 --> 607 columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
